Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	adaptive_boosting_cross_validation
	1	combined_results
	1	decision_tree_cross_validation
	1	logistic_regression_cross_validation
	1	random_forest_cross_validation
	1	svm_cross_validation
	1	xgboost_cross_validation
	7

[Sat Aug  8 09:49:18 2020]
rule logistic_regression_cross_validation:
    input: output_data/heart_disease_data_x_train_replaced.csv, output_data/heart_disease_data_y_train.csv
    output: output_cv/logistic_regression_cross_validation.csv
    jobid: 1


[Sat Aug  8 09:49:18 2020]
rule random_forest_cross_validation:
    input: output_data/heart_disease_data_x_train_replaced.csv, output_data/heart_disease_data_y_train.csv
    output: output_cv/random_forest_cross_validation.csv
    jobid: 3

[Sat Aug  8 09:49:18 2020]
Error in rule logistic_regression_cross_validation:
    jobid: 1
    output: output_cv/logistic_regression_cross_validation.csv
    shell:
        python logistic_regression_cross_validation.py
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Terminating processes on user request, this might take some time.
[Sat Aug  8 09:49:23 2020]
Error in rule random_forest_cross_validation:
    jobid: 3
    output: output_cv/random_forest_cross_validation.csv
    shell:
        python random_forest_cross_validation.py
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: /Users/neha/Horizon/Horizon_Project/Heart_Disease/.snakemake/log/2020-08-08T094918.362568.snakemake.log
